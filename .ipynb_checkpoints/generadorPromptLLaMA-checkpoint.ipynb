{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce20cd65-9115-442f-a75e-9b8f6d81153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ollama import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79c8010-7b39-4797-b253-b94c234bd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el cliente Ollama (por defecto corre en localhost:11434)\n",
    "client = Client()\n",
    "\n",
    "def generar_historias_llama(json_input_file, json_output_file, prompt_base):\n",
    "    with open(json_input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        issues = json.load(f)\n",
    "\n",
    "    for issue in issues:\n",
    "        title = issue.get(\"title\", \"\")\n",
    "        body = issue.get(\"body\", \"\")\n",
    "        state = issue.get(\"state\", \"\")\n",
    "        author = issue.get(\"user\", \"\")\n",
    "        created = issue.get(\"created_at\", \"\")\n",
    "        issue_number = issue.get(\"number\", \"\")\n",
    "\n",
    "        context_lines = []\n",
    "        context_lines.append(f\"Issue #{issue_number} reportado por {author} (creado el {created}):\\n\")\n",
    "        context_lines.append(f\"Título: {title}\\n\")\n",
    "        context_lines.append(f\"Descripción:\\n{body}\\n\")\n",
    "        context_lines.append(f\"Estado: {state}\\n\")\n",
    "        context_lines.append(\"Comentarios:\")\n",
    "\n",
    "        comments = issue.get(\"comments\", [])\n",
    "        if comments:\n",
    "            for comment in comments:\n",
    "                c_author = comment.get(\"user\", \"\")\n",
    "                c_date = comment.get(\"created_at\", \"\")\n",
    "                c_body = comment.get(\"body\", \"\").strip()\n",
    "                context_lines.append(f\"- {c_author} ({c_date}): {c_body}\")\n",
    "        else:\n",
    "            context_lines.append(\"- No hay comentarios.\")\n",
    "\n",
    "        full_prompt = \"\\n\".join(context_lines) + \"\\n\\n\" + prompt_base\n",
    "\n",
    "        print(f\"Generando historia de usuario para issue #{issue_number}...\")\n",
    "\n",
    "        #llamar al modelo LLM\n",
    "        completion = client.chat(\n",
    "            #model=\"llama3\",  # aca va modelo que descargue con `ollama pull llama3` es el mejor 5gb de ram y requiere grafica\n",
    "            model=\"tinyllama\", # modelo liviano `ollama pull tinyllama` es el mejor 1.5gb de ram y anda en cpu\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Eres un experto en redacción de historias de usuario.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": full_prompt\n",
    "                }\n",
    "            ],\n",
    "            options={\n",
    "                \"temperature\": 0.2\n",
    "            }\n",
    "        )\n",
    "\n",
    "        respuesta = completion[\"message\"][\"content\"].strip()\n",
    "        issue[\"historia_usuario\"] = respuesta\n",
    "\n",
    "    with open(json_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(issues, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Historias generadas y guardadas en '{json_output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdae0b-4e82-469f-9c91-5aacc2a56a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\",\n",
    "prompt_base = \"Por favor, genera una historia de usuario detallada basada en este issue.\"\n",
    "generar_historias_llama(\"issuesComments.json\", \"issues_con_historias.json\", prompt_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5553d7fe-3347-403e-99e8-cea5d164192c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Ent_Virtual]",
   "language": "python",
   "name": "conda-env-Ent_Virtual-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
